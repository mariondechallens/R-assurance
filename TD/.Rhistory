ytrain = read.csv(paste0(data_folder,"train_y.csv"))
yrandom = read.csv(paste0(data_folder,"sample_submission.csv"))
xtrain = h5file(name = paste0(data_folder,"train.h5/train.h5"))
xtest = h5file(name = paste0(data_folder,"test.h5/test.h5"))
## fichiers à charger
source(paste0(file_folder,"fonctions_final.R"))
source(paste0(file_folder,"features_final.R"))
dfw = rassembler_feat() #entropie de Renyi et écart types sur décompo en ondelettes des eeg
df_abs = read.csv(paste0(data_folder,"basic_abs.csv")) #basic features (min/max de la val absolue du signal)
dfp = rassembler_feat_prop()  # proportions des ondes alpha, theta etc sur eeg
dfa = rassembler_feat_alpha() # features sur ondes alpha (eeg)
df = rassembler_feat_freq()  # features sur andes de frequences alpha theta etc sur eeg
df[is.na(df)] = 0 #setting NA values to zero
df = merge(df,dfw, by =c("id","sleep_stage"),all.x = TRUE, all.y = TRUE)
df = merge(df,df_abs, by =c("id","sleep_stage"),all.x = TRUE, all.y = TRUE)
df = merge(df,dfa, by =c("id","sleep_stage"),all.x = TRUE, all.y = TRUE)
df = merge(df,dfp, by =c("id","sleep_stage"),all.x = TRUE, all.y = TRUE)
f_RandomForest = randomForest(sleep_stage~.,data=df[,2:ncol(df)],mtry = 128)
print(f_RandomForest)
imp = as.data.frame(f_RandomForest$importance[order(f_RandomForest$importance[, 1],
decreasing = TRUE), ])
write.csv(imp,file = paste0(data_folder,"imp2.csv"),row.names = TRUE)
View(imp)
imp2 = read.csv(paste0(data_folder,"imp2.csv"))
View(imp2)
f_RandomForest2 = randomForest(sleep_stage~.,
data=df[,c("sleep_stage",subset(imp,imp[,2] > 150)[,1])],ntree=700,mtry = 48)
print(f_RandomForest2)
imp = read.csv(paste0(data_folder,"imp2.csv"))
imp[,1] = as.character(imp[,1])
f_RandomForest2 = randomForest(sleep_stage~.,
data=df[,c("sleep_stage",subset(imp,imp[,2] > 150)[,1])],ntree=700,mtry = 48)
print(f_RandomForest2)
rm(f_RandomForest)
f_RandomForest3 = randomForest(sleep_stage~.,
data=df[,c("sleep_stage",subset(imp,imp[,2] > 100)[,1])],ntree=700,mtry = 48)
print(f_RandomForest3)
dft = rassembler_feat(train = FALSE) ##ent Renyi et sd sur vaguelettes
df_alp = rassembler_feat_alpha(train = FALSE)
dftp = rassembler_feat_prop(train = FALSE)
abs_t = read.csv(paste0(data_folder,"basic_abs_test.csv"))
dftest = rassembler_feat_freq(train = FALSE)
dftest[is.na(dftest)] = 0 #setting NA values to zero
dftest = cbind(dftest,dft)
dftest = cbind(dftest,abs_t)
dftest = cbind(dftest,df_alp)
dftest = cbind(dftest,dftp)
ytest = as.data.frame(predict(f_RandomForest3,dftest[,subset(imp,imp[,2] > 100)[,1]]))
ytest = cbind(yrandom[,1],ytest)
colnames(ytest) =  c("id","sleep_stage")
write.csv(ytest,file = paste0(data_folder,"ytest_final.csv"),row.names = FALSE)
print(f_RandomForest2)
rm(f_RandomForest2)
f_RandomForest2 = randomForest(sleep_stage~.,
data=df[,c("sleep_stage",subset(imp,imp[,2] > 150)[,1])],ntree=900,mtry = 48)
print(f_RandomForest2)
rm(f_RandomForest2)
f_RandomForest2 = randomForest(sleep_stage~.,
data=df[,c("sleep_stage",subset(imp,imp[,2] > 100)[,1])],ntree=900,mtry = 48)
print(f_RandomForest2)
print(f_RandomForest3)
subset(imp,imp[,2] > 100)[,1])
subset(imp,imp[,2] > 100)[,1]
hist(f_RandomForest3$oob.times)
varImpPlot(f_RandomForest3)
c = (0,0,2,3,3,3)
c = seq(1,8)
c[-1]
library(VGAM)
install.packages(VGAM)
install.packages("VGAM")
library(VGAM)
library(ggplot2)
CountGroups <- function(seq) {
# counts the number of groups of a sequence of tossing
n_groups <- 1
if (length(seq) != 1) {
for (j in 1 : (length(seq) - 1)) {
if (seq[j] != seq[j + 1]) {
n_groups <- n_groups + 1
}
}
}
return(n_groups)
}
ProbaExceedingXGroups <- function(n, X, nrep) {
favorable_cases <- 0
for (j in 1:nrep) {
toss <- rbinom(n, 1, 0.6) # o sample(c(0,1),n,replace=TRUE)
favorable_cases <- favorable_cases + as.integer(CountGroups(toss) > X)
}
proba <- favorable_cases / nrep
return(proba)
}
ProbaExceedingXGroups(10,5,10000)
ExpectationNumberGroups <- function(n, nrep) {
sum_values <- 0
for (j in 1:nrep) {
toss <- rbinom(n, 1, 0.6)
sum_values <- sum_values + CountGroups(toss)
}
expected_number <- sum_values / nrep
return(expected_number)
}
ExpectationNumberGroups(10, 10000)
montyhall <- function(strategy_change, nrep) {
# compute probability of winning for both strategies
# strategy_change == TRUE means change
# strategy_change == FALSE means staying
win <- 0
for(i in 1: nrep){
car <- sample(c(1,2,3),1) # production chooses where to put the car
chosen <- sample(c(1,2,3),1) # participant chooses a door
if (!strategy_change) {
win <- win + (car == chosen) # sum one if the car is under chosen door
}else{
if (car == chosen) { # open any of the other doors
open_door <- sample(setdiff(c(1,2,3),chosen),1,prob=c(0.5,0.5))
} else { # open the door with a goat
open_door <- setdiff(c(1,2,3),c(car,chosen))
}
win <- win + (car == setdiff(c(1,2,3),c(chosen,open_door)))
}
}
return(win/nrep)
}
startegy_change = TRUE
(!stqrtegy_change)
(!startegy_change)
car <- sample(c(1,2,3),1) # production chooses where to put the car
chosen <- sample(c(1,2,3),1) # participant chooses a door
open_door <- sample(setdiff(c(1,2,3),chosen),1,prob=c(0.5,0.5))
setdiff(c(1,2,3),chosen)
chosen <- sample(c(1,2,3),1) # participant chooses a door
open_door <- setdiff(c(1,2,3),c(car,chosen))
montyhall(TRUE, 10000) # prob of winning changing
montyhall(FALSE, 10000) # prob of winning staying
data_1 <- c(2.5, 1.8, 2.9, 0.9, 2.1, 1.7, 2.2, 2.8)
mean(data_1)
a_est <- mean(data_1^2/2)
f_ray_inv <- function (y, a) {
return(sqrt(-2*a*log(1-y)))
}
mean(f_ray_inv(runif(10000), a_est))
mean(rrayleigh(10000, sqrt(a_est)))
n <- 100
n_B <- 1000
estimators <- rep(NA, n_B)
for (i in 1:n_B) {
estimators[i] <- mean((rrayleigh(n, sqrt(a_est)))^2/2)
}
mean(estimators)
a_est
var(estimators)
I = n/a_est^2
I = n/a_est^2  #Information de Fisher
1/I
var(estimators)
simulated_normal <- (estimators - a_est)/sqrt(var(estimators))
ggplot() +
geom_histogram(aes(x= simulated_normal, y=..density..)) +
geom_density(aes(x=rnorm(10000)), color="black", size=1.2) +
ggtitle("Checking asymptotical normality") +
xlab("")
library(VGAM)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/Rintro+app.R', echo=TRUE)
pi
3**2
M = matrix(data = NA,nrow = length(X),ncol = length(p))
m= matrix(data = NA,nrow = 2,ncol = 2)
View(m)
m(1)
m[1]
m[1,2]
m(2,2)
c = rep(1,5)
sum(c)
m[1,1] =1
m[1,2] =2
m[2,2] =4
m[2,1] =4
m
m[2,1] =3
m
sum(m[,1])
sum(m[1,])
c = c(2,2)
sum(m[,1]*c)
m[,1]*c
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
distr = sample(c(0,1),1000,c(0.3,0.7),replace = TRUE)
mixture = distr*rnorm(1000)+(1-distr)*rnorm(1000,4,0.75)
mixture
distr = sample(c(0,1),1000,c(0.3,0.7),replace = TRUE)
mixture = distr*rnorm(1000)+(1-distr)*rnorm(1000,4,0.75)
p0 = c(0.5,0.5)
m0 = c(0,0)
sigma0 = c(1,1)
res = EM(mixturep0,m0,sigma0,0.01)
res = EM(mixture,p0,m0,sigma0,0.01)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
e = 100
(e>0.01)
EM = function(X,mu0,p0,sigma0,epsilon)
{
p = p0
mu = mu0
sigma =sigma0
e = 100
if (e > epsilon)
{
muold = mu
sigmaold = sigma
M = proba(p,mu,sigma,X)  #E step
thetamax = argmax(M,X) #M step
p = thetamax$pmax
mu = thetamax$mmax
sigma = thetamax$sigmamax
e = (muold - mu)**2 + (sigmaold -sigma)**2
}
return(list('p' = p, 'm' = mu, 'sigma' = sigma ))
}
res = EM(mixture,p0,m0,sigma0,0.01)
res$p
res$mu
X = mixture
p = p0
mu = mu0
sigma =sigma0
mu0 = c(0,0)
res = EM(mixture,mu0,p0,sigma0,0.01)
res$mu
p = p0
mu = mu0
sigma =sigma0
M = proba(p,mu,sigma,X)  #E step
thetamax = argmax(M,X) #M step
p = thetamax$pmax
EM = function(X,mu0,p0,sigma0,epsilon)
{
p = p0
mu = mu0
sigma =sigma0
e = 100
while (e > epsilon)
{
muold = mu
sigmaold = sigma
M = proba(p,mu,sigma,X)  #E step
thetamax = argmax(M,X) #M step
p = thetamax$p
mu = thetamax$mu
sigma = thetamax$sigma
e = (muold - mu)**2 + (sigmaold -sigma)**2
}
return(list('p' = p, 'm' = mu, 'sigma' = sigma ))
}
dis
res = EM(mixture,mu0,p0,sigma0,0.01)
res$m
res$m
res$p
res$sigma
res = EM(mixture,mu0,p0,sigma0,0.0001)
res$m
res$p
res$sigma
p = p0
mu = mu0
sigma =sigma0
e = 100
muold = mu
sigmaold = sigma
M = proba(p,mu,sigma,X)  #E step
thetamax = argmax(M,X) #M step
p = thetamax$p
mu = thetamax$mu
sigma = thetamax$sigma
e = (muold - mu)**2 + (sigmaold -sigma)**2
muold = mu
sigmaold = sigma
M = proba(p,mu,sigma,X)  #E step
thetamax = argmax(M,X) #M step
p = thetamax$p
mu = thetamax$mu
sigma = thetamax$sigma
e = (muold - mu)**2 + (sigmaold -sigma)**2
EM = function(X,mu0,p0,sigma0,iter)
{
p = p0
mu = mu0
sigma =sigma0
for (i in 1:iter)
{
muold = mu
sigmaold = sigma
M = proba(p,mu,sigma,X)  #E step
thetamax = argmax(M,X) #M step
p = thetamax$p
mu = thetamax$mu
sigma = thetamax$sigma
}
return(list('p' = p, 'm' = mu, 'sigma' = sigma ))
}
res = EM(mixture,mu0,p0,sigma0,100)
res$m
res$p
res$sigma
p0[2]
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
library(imager)
EM = function(X,mu0,p0,sigma0,iter)
{
p = p0
mu = mu0
sigma =sigma0
for (i in 1:iter)
{
M = proba(p,mu,sigma,X)  #E step
thetamax = argmax(M,X) #M step
p = thetamax$p
print(p)
mu = thetamax$mu
sigma = thetamax$sigma
}
return(list('p' = p, 'm' = mu, 'sigma' = sigma ))
}
res = EM(mixture,mu0,p0,sigma0,10)
EM = function(X,mu0,p0,sigma0,iter)
{
p = p0
mu = mu0
sigma =sigma0
for (i in 1:iter)
{
M = proba(p,mu,sigma,X)  #E step
print(head(M))
thetamax = argmax(M,X) #M step
p = thetamax$p
# print(p)
mu = thetamax$mu
sigma = thetamax$sigma
}
return(list('p' = p, 'm' = mu, 'sigma' = sigma ))
}
res = EM(mixture,mu0,p0,sigma0,10)
proba = function(p,mu, sigma, X)
{
M = matrix(data = NA,nrow = length(X),ncol = length(p0))
for (i in 1:length(X))
{
denom = sum(p*gauss_f(rep(X[i],length(p)),mu,sigma))
print(denom)
for (k in 1:length(p))
{
M[i,k] = p[k]*gauss_f(X[i],mu[k],sigma[k])/denom
}
}
return(M)
}
res = EM(mixture,mu0,p0,sigma0,10)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
EM2 = function(data,K,max_iter)
{
n = length(data)
means = sample(data,K,replace = FALSE)
sigmas = rep(1,K)
prop = rep(1/K,K)
prop = matrix(rep(0,n*K),ncol = K)
for (ite in 1:max_ite)
{
for (k in 1:K) # E step
{
prop[,k] = prop[k]*dnorm(data,means[k],sigmas[k])
}
prob = prob / apply(prob,1,sum)
# M step
prop = apply(prob,2,mean)
for (k in 1:K){
means[k] = mean(prob[,k]*data)
}
for (k in 1:K) {
sigmas[k] = sqrt(mean(prob[,k]*(data -means[k])**2) / prop[k])
}
}
return(list('prop' = prop, 'means' = means, 'sigmas' = sigmas, 'prob' = prob))
}
res2 = EM2(2,mixture,10)
res2$means
res2$prop
res2$sigmas
res2 = EM2(mixture,2,10)
EM2 = function(data,K,max_iter)
{
n = length(data)
means = sample(data,K,replace = FALSE)
sigmas = rep(1,K)
prop = rep(1/K,K)
prop = matrix(rep(0,n*K),ncol = K)
for (ite in 1:max_iter)
{
for (k in 1:K) # E step
{
prop[,k] = prop[k]*dnorm(data,means[k],sigmas[k])
}
prob = prob / apply(prob,1,sum)
# M step
prop = apply(prob,2,mean)
for (k in 1:K){
means[k] = mean(prob[,k]*data)
}
for (k in 1:K) {
sigmas[k] = sqrt(mean(prob[,k]*(data -means[k])**2) / prop[k])
}
}
return(list('prop' = prop, 'means' = means, 'sigmas' = sigmas, 'prob' = prob))
}
res2 = EM2(mixture,2,10)
res2$means
res2$prop
res2$sigmas
EM2 = function(data,K,max_iter)
{
n = length(data)
means = sample(data,K,replace = FALSE)
sigmas = rep(1,K)
prop = rep(1/K,K)
prob = matrix(rep(0,n*K),ncol = K)
for (ite in 1:max_iter)
{
for (k in 1:K) # E step
{
prob[,k] = prop[k]*dnorm(data,means[k],sigmas[k])
}
prob = prob / apply(prob,1,sum)
# M step
prop = apply(prob,2,mean)
for (k in 1:K){
means[k] = mean(prob[,k]*data) /prop[k]
}
for (k in 1:K) {
sigmas[k] = sqrt(mean(prob[,k]*(data -means[k])**2) / prop[k])
}
}
return(list('prop' = prop, 'means' = means, 'sigmas' = sigmas, 'prob' = prob))
}
res2 = EM2(mixture,2,10)
res2$means
res2$prop
res2$sigmas
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
res = EM(mixture,mu0,p0,sigma0,100)
res$m
res$p
res$sigma
res2 = EM2(mixture,2,100)
res2$means
res2$prop
res2$sigmas
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
source('~/Centrale Paris/3A/OMA/Statistiques avancées/EM.R', echo=TRUE)
cluster = as.factor(apply(res$M, 1, which.max))
ggplot() +
geom_line(aes(x=mixture), color="black", size=1.2, stat="density")+
geom_point(aes(x = mixture, color = cluster), y = 0, size = 0.6)
library(ggplo)
library(ggplot2)
ggplot() +
geom_line(aes(x=mixture), color="black", size=1.2, stat="density")+
geom_point(aes(x = mixture, color = cluster), y = 0, size = 0.6)
install.packages("imager")
library(imager)
train = load.image(here::here("fig","train.jpg"))
train = load.image(imager::imager("fig","train.jpg"))
train = load.image(("fig","train.jpg"))
install.packages("here")
library(here)
train = load.image(here::here("fig","train.jpg"))
train = resize_halfXY(resize_halfXY(train)) # resize
plot(train)
train = load.image(here::here("fig","train.jpg"))
train = load.image(here::here("fig","train.jpg"))  #doesn't work
source('~/GitHub/Reassurance/TD_2_rea.R', echo=TRUE)
setwd("~/GitHub/Reassurance")
data = read.csv2("C:/Users/Admin/Documents/Centrale Paris/3A/OMA/Réassurance/TD 2/DATABASE.csv",sep = ";", dec=",")
nb_evt = aggregate(EVT~surva, data = data, n_distinct) #nb d'evt par annee
source('~/GitHub/Reassurance/TD_2_rea.R', echo=TRUE)
source('~/GitHub/Reassurance/TD_2_rea.R', echo=TRUE)
ineq(pred2,type='Gini')
plot(Lc(pred2))
glm1 =  glm(CHARGE~engt_axa, family=gaussian("identity"), data=train)
summary(glm1)
pred2 =  predict(glm1,test, type="response")
plot(test$engt_axa,test$CHARGE, type = "l")
lines(test$engt_axa,pred2, col='blue')
param=plot.gbm(gbm1, i.var = 1, lwd = 2, col = "blue", main = "Perte",xlim=range(1:600000))
param
gbm.perf(gbm1)
ineq(pred3,type='Gini')  # plus inégalitaire que les deux autres
plot(Lc(pred3)) # plus inégalitaire que les deux autres
